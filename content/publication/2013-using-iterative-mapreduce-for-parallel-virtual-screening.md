+++
author_keywords = "Big Data;  Chemoinformatics;  MapReduce;  Parallel SVM;  Spark"
note = "cited By 0"
doi = "10.1109/CloudCom.2013.99"
url = "/publication/2013-mapreduce-vs"
title = "Using iterative MapReduce for parallel virtual screening"
url_html = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899736110&partnerID=40&md5=d7961d818897ff147269a4822ac47264"
journal = "Proceedings of the International Conference on Cloud Computing Technology and Science, CloudCom"
author = "Ahmed L, Edlund A, Laure E, Spjuth O"
abstract = "Virtual Screening is a technique in chemo informatics used for Drug discovery by searching large libraries of molecule structures. Virtual Screening often uses SVM, a supervised machine learning technique used for regression and classification analysis. Virtual screening using SVM not only involves huge datasets, but it is also compute expensive with a complexity that can grow at least up to O(n2). SVM based applications most commonly use MPI, which becomes complex and impractical with large datasets. As an alternative to MPI, MapReduce, and its different implementations, have been successfully used on commodity clusters for analysis of data for problems with very large datasets. Due to the large libraries of molecule structures in virtual screening, it becomes a good candidate for MapReduce. In this paper we present a MapReduce implementation of SVM based virtual screening, using Spark, an iterative MapReduce programming model. We show that our implementation has a good scaling behaviour and opens up the possibility of using huge public cloud infrastructures efficiently for virtual screening. Â© 2013 IEEE."
volume = "2"
source = "Scopus"
art_number = "6735391"
year = "2013"
date = "2013-12-02"
keywords = "Cloud computing;  Electric sparks;  Iterative methods;  Libraries;  Molecules, Big datum;  Chemoinformatics;  Classification analysis;  Commodity clusters;  Iterative mapreduce;  Map-reduce;  Parallel SVM;  Supervised machine learning, Digital libraries"
document_bibtex_type = "Conference Paper"
pages = "27-32"
+++

