+++
note = "cited By 9"
doi = "10.1186/1471-2105-9-360"
url = "/publication/2008-c1c2"
aliases = ["publication/2008-c1c2"]
title = "The C1C2: A framework for simultaneous model selection and assessment"
url_html = "https://www.scopus.com/inward/record.uri?eid=2-s2.0-52949118135&partnerID=40&md5=ab269808b3362e659dba6a5c48fe356a"
journal = "BMC Bioinformatics"
author = "Eklund, M. and Spjuth, O. and Wikberg, J.E.S."
volume = "9"
source = "Scopus"
art_number = "360"
year = "2008"
keywords = "Automatic searches;  Generalization Error;  Independent variables;  K fold cross validations;  Predictive modeling;  Real-world datasets;  Simultaneous model;  Variable selection, Genetic algorithms, Estimation, citrinin;  proteinase inhibitor, accuracy;  analytical error;  article;  bioinformatics;  conceptual framework;  controlled study;  correlation function;  dependent variable;  genetic algorithm;  independent variable;  information retrieval;  intermethod comparison;  mathematical model;  physical chemistry;  quantitative structure activity relation;  simulation;  statistical model;  algorithm;  biological model;  computer simulation;  data base;  factual database;  information retrieval;  methodology;  statistical analysis;  statistical model, Algorithms;  Computer Simulation;  Data Interpretation, Statistical;  Database Management Systems;  Databases, Factual;  Information Storage and Retrieval;  Models, Biological;  Models, Statistical"
document_bibtex_type = "Article"
abstract = "Background: There has been recent concern regarding the inability of predictive modeling approaches to generalize to new data. Some of the problems can be attributed to improper methods for model selection and assessment. Here, we have addressed this issue by introducing a novel and general framework, the C1C2, for simultaneous model selection and assessment. The framework relies on a partitioning of the data in order to separate model choice from model assessment in terms of used data. Since the number of conceivable models in general is vast, it was also of interest to investigate the employment of two automatic search methods, a genetic algorithm and a brute-force method, for model choice. As a demonstration, the C1C2 was applied to simulated and real-world datasets. A penalized linear model was assumed to reasonably approximate the true relation between the dependent and independent variables, thus reducing the model choice problem to a matter of variable selection and choice of penalizing parameter. We also studied the impact of assuming prior knowledge about the number of relevant variables on model choice and generalization error estimates. The results obtained with the C1C2 were compared to those obtained by employing repeated K-fold cross-validation for choosing and assessing a model. Results: The C1C2 framework performed well at finding the true model in terms of choosing the correct variable subset and producing reasonable choices for the penalizing parameter, even in situations when the independent variables were highly correlated and when the number of observations was less than the number of variables. The C1C2 framework was also found to give accurate estimates of the generalization error. Prior information about the number of important independent variables improved the variable subset choice but reduced the accuracy of generalization error estimates. Using the genetic algorithm worsened the model choice but not the generalization error estimates, compared to using the brute-force method. The results obtained with repeated K-fold cross-validation were similar to those produced by the C1C2 in terms of model choice, however a lower accuracy of the generalization error estimates was observed. Conclusion: The C1C2 framework was demonstratedto work well for finding the true model within a penalized linear model class and accurately assess its generalization error, even for datasets with many highly correlated independent variables, a low observation-to-variable ratio, and model assumption deviations. A complete separation of the model choice and the model assessment in terms of data used for each task improves the estimates of the generalization error. \u00a9 2008 Eklund et al; licensee BioMed Central Ltd."
+++

